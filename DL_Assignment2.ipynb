{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode='coarse')\n",
        "testX = preprocess_input(testX)\n",
        "trainX = preprocess_input(trainX)"
      ],
      "metadata": {
        "id": "pfRlntrFA68z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. VGG16 Model"
      ],
      "metadata": {
        "id": "x3Bzgl0t99aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "vgg16_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = vgg16_base_model.input\n",
        "    x = vgg16_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    vgg16_model = Model(inputs, outputs, name='VGG16')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = vgg16_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeEiED9RD7_E",
        "outputId": "be9e2011-a9da-4b65-c4a9-b99ef8646bb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
            "Accuracy: 0.0609\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0523\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0630\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0595\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. VGG19 Model"
      ],
      "metadata": {
        "id": "wp6PdVet-LBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "vgg19_base_model = VGG19(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "vgg19_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = vgg19_base_model.input\n",
        "    x = vgg19_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    vgg16_model = Model(inputs, outputs, name='VGG19')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = vgg16_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ3mYEW4-NG7",
        "outputId": "e127ccab-d841-49e1-e44f-5ed00f7918dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "Accuracy: 0.0439\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "Accuracy: 0.0482\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "Accuracy: 0.0503\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "Accuracy: 0.0650\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
            "Accuracy: 0.0604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ReseNet50 Model"
      ],
      "metadata": {
        "id": "5lNfO4i_-3dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "resnet50_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "resnet50_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = resnet50_base_model.input\n",
        "    x = resnet50_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    resnet50_model = Model(inputs, outputs, name='VGG19')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = resnet50_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkMosSoa-6DB",
        "outputId": "24de166c-8d15-444d-c63e-1f82d3675422"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step\n",
            "Accuracy: 0.0596\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step\n",
            "Accuracy: 0.0503\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step\n",
            "Accuracy: 0.0398\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step\n",
            "Accuracy: 0.0463\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step\n",
            "Accuracy: 0.0442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. MobileNet Model"
      ],
      "metadata": {
        "id": "_gkuIkIkB1d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "mobileNet_base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "mobileNet_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = mobileNet_base_model.input\n",
        "    x = mobileNet_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    mobileNet_model = Model(inputs, outputs, name='VGG19')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = mobileNet_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuQ4as6-B4Fx",
        "outputId": "6c13bd39-1bf4-4cfb-b4b3-6775f2ee5c21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2258ef0399f2>:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  mobileNet_base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0462\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
            "Accuracy: 0.0466\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0534\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
            "Accuracy: 0.0505\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
            "Accuracy: 0.0476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. MobileNetV2 Model"
      ],
      "metadata": {
        "id": "8K9Mzbr6Ctiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "mobileNetv2_base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "mobileNetv2_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = mobileNetv2_base_model.input\n",
        "    x = mobileNetv2_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    mobileNetv2_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = mobileNetv2_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9FtnHWbCwcc",
        "outputId": "5fafa8df-edd9-403a-e37d-f5b4d93001ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7e1974481fa5>:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  mobileNetv2_base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step\n",
            "Accuracy: 0.0477\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step\n",
            "Accuracy: 0.0424\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step\n",
            "Accuracy: 0.0458\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step\n",
            "Accuracy: 0.0534\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step\n",
            "Accuracy: 0.0482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. DenseNet121 Model\n"
      ],
      "metadata": {
        "id": "wQVrMVHYD4lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "denseNet121_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "denseNet121_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = denseNet121_base_model.input\n",
        "    x = denseNet121_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    denseNet121_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = denseNet121_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0z2Y_edD-lW",
        "outputId": "00efa545-cffc-46ae-ceb9-8796845cfda8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 45ms/step\n",
            "Accuracy: 0.0407\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 46ms/step\n",
            "Accuracy: 0.0497\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 42ms/step\n",
            "Accuracy: 0.0438\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 42ms/step\n",
            "Accuracy: 0.0344\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 45ms/step\n",
            "Accuracy: 0.0451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. DenseNet201 Model"
      ],
      "metadata": {
        "id": "3tCmd_VkFAEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "size = 32\n",
        "# Load VGG16 base model\n",
        "denseNet201_base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "denseNet201_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = denseNet201_base_model.input\n",
        "    x = denseNet201_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    denseNet201_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = denseNet201_model.predict(testX, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAWFu7LFDFf",
        "outputId": "a6df3428-6025-41c8-98c3-ce36d6235928"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 90ms/step\n",
            "Accuracy: 0.0403\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 86ms/step\n",
            "Accuracy: 0.0577\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 86ms/step\n",
            "Accuracy: 0.0500\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 86ms/step\n",
            "Accuracy: 0.0393\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 85ms/step\n",
            "Accuracy: 0.0523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.     InceptionNetV3 Model"
      ],
      "metadata": {
        "id": "aXsrE4DiFw0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "testX_resized = np.array([cv2.resize(img, (224, 224)) for img in testX])\n",
        "testX_resized = preprocess_input(testX_resized)\n",
        "\n",
        "size = 224\n",
        "# Load VGG16 base model\n",
        "inceptionv3_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "inceptionv3_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = inceptionv3_base_model.input\n",
        "    x = inceptionv3_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    inceptionv3_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = inceptionv3_model.predict(testX_resized, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm6cnTKqF47b",
        "outputId": "6ee7b4ae-9892-4d2c-e7b3-ac0eae9eef1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Xception Model"
      ],
      "metadata": {
        "id": "P8mmBVj5JZ8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import cv2\n",
        "import numpy as np\n",
        "(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "testX_resized = np.array([cv2.resize(img, (224, 224)) for img in testX])\n",
        "# testX_resized = preprocess_input(testX_resized)\n",
        "\n",
        "size = 224\n",
        "# Load VGG16 base model\n",
        "xception_base_model = Xception(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "xception_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = xception_base_model.input\n",
        "    x = xception_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    xception_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = xception_model.predict(testX_resized, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H5h0OZpJhcT",
        "outputId": "79848802-2d0b-4e39-84a1-ea3f3668e8fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 126ms/step\n",
            "Accuracy: 0.0633\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 118ms/step\n",
            "Accuracy: 0.0509\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 122ms/step\n",
            "Accuracy: 0.0500\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 118ms/step\n",
            "Accuracy: 0.0516\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 119ms/step\n",
            "Accuracy: 0.0424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. NasNet Model\n"
      ],
      "metadata": {
        "id": "I4dNnIJuKk4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import NASNetMobile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "testX_resized = np.array([cv2.resize(img, (224, 224)) for img in testX])\n",
        "# testX_resized = preprocess_input(testX_resized)\n",
        "\n",
        "size = 224\n",
        "# Load VGG16 base model\n",
        "nasNet_base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "nasNet_base_model.trainable = False\n",
        "\n",
        "for activation in ['softmax', 'sigmoid', 'relu','tanh', 'linear']:\n",
        "    print(f\"\\nTesting activation: {activation}\")\n",
        "\n",
        "    # Add custom classification head\n",
        "    inputs = nasNet_base_model.input\n",
        "    x = nasNet_base_model.output\n",
        "    x = Flatten()(x)\n",
        "    #x = Dense(64, activation = 'relu')(x)\n",
        "    #x = Dense(32, activation = 'relu')(x)\n",
        "    outputs = Dense(20, activation=activation)(x)\n",
        "    nasNet_model = Model(inputs, outputs, name='MobilenetV2')\n",
        "    #model.summary(show_trainable=True)\n",
        "\n",
        "\n",
        "    y_pred_probs = nasNet_model.predict(testX_resized, verbose=1)\n",
        "\n",
        "    if activation == 'softmax':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'sigmoid':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'relu':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    elif activation == 'tanh':\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Flatten y_test if needed\n",
        "    y_true = testY.flatten()\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4gFhoMjKnh8",
        "outputId": "0ac66032-06c7-4b41-8b62-5aec6364d3b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing activation: softmax\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 92ms/step\n",
            "Accuracy: 0.0535\n",
            "\n",
            "Testing activation: sigmoid\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step\n",
            "Accuracy: 0.0505\n",
            "\n",
            "Testing activation: relu\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step\n",
            "Accuracy: 0.0419\n",
            "\n",
            "Testing activation: tanh\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 92ms/step\n",
            "Accuracy: 0.0529\n",
            "\n",
            "Testing activation: linear\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step\n",
            "Accuracy: 0.0540\n"
          ]
        }
      ]
    }
  ]
}